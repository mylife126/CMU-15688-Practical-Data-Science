{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relational Data and Visualization\n",
    "In this problem, you will be analyzing the Twitter data we extracted using [this](https://dev.twitter.com/overview/api) api. The data consists of Twitter users (with unique handles) and their attributes (e.g., number of followers), some recent tweets posted by them with attributes (e.g., time stamp, number of retweets), and the follow relationship between the users. These are available in the three (gzipped) CSV files provided to you:\n",
    "- users.csv.gz - users, user attributes\n",
    "- edges.csv.gz - follow edges (directed, an edge from A to B means A follows B or B is a friend of A)\n",
    "- tweets.csv.gz - tweets posted by the users along with its attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import gzip\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib\n",
    "# Use svg backend for better quality\n",
    "matplotlib.use(\"svg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "if not os.environ.get(\"DISABLE_TESTING\", False):\n",
    "    %matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 5.0) # you should adjust this to fit your screen\n",
    "from testing.testing import test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Relational Data\n",
    "This question will guide you through loading Twitter data into an in-memory SQLite database and running some basic queries on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Task A: Load Twitter data into SQLite database\n",
    "Your first task is to use the (gzipped) csv and sqlite3 python packages to load the three csv files we give you as relations (or tables) into an SQLite in-memory database.\n",
    "\n",
    "Loading the data from (gzipped) csv file into the database involves the following steps:\n",
    "1. Identify the schema of the table (for this problem, you will only need TEXT and INTEGER attribute types)\n",
    "2. Create a table with the identified schema\n",
    "3. Load the contents of csv in memory\n",
    "4. Insert every row of csv file as a record in the table\n",
    "\n",
    "You can refer to [sqlite3 documentation](https://docs.python.org/2/library/sqlite3.html) and the class lecture for steps 2 and 4. For step 3, refer to the [csv documentation](https://docs.python.org/2/library/csv.html). Be sure to name your tables `users`, `edges`, and `tweets`. \n",
    "\n",
    "Make sure to commit (the equivalent of Ctrl+S for databases) any changes you make to the database. [This](https://www.techopedia.com/definition/16/commit) page should give you an idea about why commit is essential.\n",
    "\n",
    "Don't decompress the `.gz` files - we do that while reading them. This is common practice when dealing with large amounts of text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TESTING load_twitter_data_sqlite3: PASSED 3/3\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Helper function to get a connection to an in memory database and load Twitter data using your implemented function\n",
    "def get_loaded_connection(load_twitter_data_sqlite3_test_impl, users_filepath, \n",
    "                         edges_filepath, tweets_filepath):\n",
    "    conn = sqlite3.connect(\":memory:\")\n",
    "    conn.text_factory = str\n",
    "    load_twitter_data_sqlite3_test_impl(conn, users_filepath, edges_filepath, tweets_filepath)\n",
    "    return conn\n",
    "\n",
    "\n",
    "def load_twitter_data_sqlite3_test(load_twitter_data_sqlite3_test_impl):\n",
    "    conn = get_loaded_connection(load_twitter_data_sqlite3_test_impl, \n",
    "                                 'users.csv.gz', 'edges.csv.gz', 'tweets.csv.gz')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Check all tables were created\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type = 'table';\")\n",
    "    test.equal(set(cursor.fetchall()), {('edges',), ('tweets',), ('users',)})\n",
    "\n",
    "    try:\n",
    "        # Check number of entries in users table\n",
    "        cursor.execute('SELECT COUNT(*) FROM users;')\n",
    "        test.equal(cursor.fetchone(), (12403,))\n",
    "    except sqlite3.OperationalError:\n",
    "        test.true(False)\n",
    "\n",
    "    try:\n",
    "        # Check user table entry\n",
    "        cursor.execute(\"SELECT screen_name FROM users WHERE name='Donald J. Trump';\")\n",
    "        test.equal(cursor.fetchone(), ('realDonaldTrump',))\n",
    "    except sqlite3.OperationalError:\n",
    "        test.true(False)\n",
    "        \n",
    "\n",
    "@test\n",
    "def load_twitter_data_sqlite3(conn, users_filepath, edges_filepath, tweets_filepath) :\n",
    "    \"\"\" Load twitter data in the three files as tables into an in-memory SQLite database\n",
    "    Input:\n",
    "        conn (sqlite3.Connection) : Connection object corresponding to the database; used to perform SQL commands.\n",
    "        users_filepath (str) : absolute/relative path to users.csv file\n",
    "        edges_filepath (str) : absolute/relative path to edges.csv file\n",
    "        tweets_filepath (str) : absolute/relative path to tweets.csv file\n",
    "    Output:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Create cursor\n",
    "    cursor = conn.cursor()\n",
    "    # Create tables\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE users (\n",
    "            name TEXT,\n",
    "            screen_name TEXT PRIMARY KEY,\n",
    "            location TEXT,\n",
    "            created_at TEXT,\n",
    "            friends_count INTEGER,\n",
    "            followers_count INTEGER,\n",
    "            statuses_count INTEGER,\n",
    "            favourites_count INTEGER\n",
    "    );\"\"\")\n",
    "    \n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE edges (\n",
    "            screen_name TEXT,\n",
    "            friend TEXT\n",
    "    );\"\"\")\n",
    "    \n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE tweets (\n",
    "            screen_name TEXT,\n",
    "            created_at TEXT,\n",
    "            retweet_count INTEGER,\n",
    "            favorite_count INTEGER,\n",
    "            text TEXT\n",
    "    );\"\"\")\n",
    "    \n",
    "    conn.commit()\n",
    "    \n",
    "    # Insert value to users\n",
    "    userInsert = []\n",
    "    with gzip.open(users_filepath,'rt', encoding = \"utf-8\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        for i, row in enumerate(reader):\n",
    "            if i!=0:\n",
    "                userInsert.append(tuple(row))\n",
    "    cursor.executemany(\"INSERT INTO users VALUES (?, ?, ?, ?, ?, ?, ?, ?);\",userInsert)\n",
    "    f.close()\n",
    "    conn.commit()\n",
    "    \n",
    "    # Insert value to edges\n",
    "    edgesInsert = []\n",
    "    with gzip.open(edges_filepath,'rt', encoding = \"utf-8\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        for i, row in enumerate(reader):\n",
    "            if i!=0:\n",
    "                edgesInsert.append(tuple(row))\n",
    "    cursor.executemany(\"INSERT INTO edges VALUES (?, ?);\", edgesInsert)\n",
    "    f.close()\n",
    "    conn.commit()\n",
    "    \n",
    "    # Insert value to tweets\n",
    "    tweetsInsert = []\n",
    "    with gzip.open(tweets_filepath,'rt', encoding = \"utf-8\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        for i, row in enumerate(reader):\n",
    "            if i!=0:\n",
    "                tweetsInsert.append(tuple(row))\n",
    "    cursor.executemany(\"INSERT INTO tweets VALUES (?, ?, ?, ?, ?);\", tweetsInsert)\n",
    "    f.close()\n",
    "    conn.commit()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Task B: Trending tweets in a topic\n",
    "Twitter is regarded as an invaluable source of valuable information. Hence, one of the favorite tasks of data miners is the analyse the trending tweets in a given topic.\n",
    "\n",
    "This task requires you to retrieve the top N most trending tweets (in descending order of trending_score) about a given topic (which is a list of keywords). The following information may be useful:\n",
    "\n",
    "- A tweet is said to be about a given topic if it contains any of the given topical phrases/keywords.\n",
    "- We will use the following simple trending_score: retweet_count + favorite_count. Tweets with higher trending_score must be ranked before the ones with lower trending_score.\n",
    "- Your result must contain unique tweets. If a tweet text occurs multiple times, display it only once with its highest trending_score.\n",
    "- Break ties by sorting the tweets in alphabetical order.\n",
    "\n",
    "The output schema should be as follows:\n",
    "\n",
    "|tweet (TEXT)| trending_score (INTEGER) |\n",
    "| :--- |:--- |\n",
    "| | |\n",
    "\n",
    "The default inputs to the function will retrieve 5 trending tweets about topic Hillary Clinton. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Modify string for filtering\n",
    "# s = '|'\n",
    "# modified_phrases = s.join(topical_phrases)\n",
    "# # Add column of trending count if allowed\n",
    "# try:\n",
    "#     cursor.execute('ALTER TABLE tweets ADD COLUMN trending_count INTEGER;')\n",
    "#     cursor.execute(\"UPDATE tweets SET trending_count = retweet_count+favorite_count;\")\n",
    "# except:\n",
    "#     pass\n",
    "# # Read all data into a pandas dataframe for sorting\n",
    "# cursor.execute('SELECT text, trending_count FROM tweets')\n",
    "# names = [x[0] for x in cursor.description]\n",
    "# rows = cursor.fetchall()\n",
    "# df = pd.DataFrame(rows, columns = names)\n",
    "# # Sort table by trending_count and text\n",
    "# df = df[df[\"text\"].str.contains(modified_phrases, case = False, regex = True)]\n",
    "# df = df.sort_values(['trending_count','text'], ascending = [False,True])\n",
    "# # Get the row id of top ranked tweets\n",
    "# df = df[:N]\n",
    "# ind = df.index.tolist()\n",
    "# ind = [x+1 for x in ind]\n",
    "# # Construct new execute command for sqlite\n",
    "# q = \"SELECT text, trending_count FROM tweets WHERE rowid IN (\"\n",
    "# for i in list(range(N)):\n",
    "#     q+='?,'\n",
    "# q= q[:-1]+');'\n",
    "\n",
    "# results = cursor.execute(q, ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TESTING trending_tweets: PASSED 1/1\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def trending_tweets_test(trending_tweets_impl):\n",
    "    conn = get_loaded_connection(load_twitter_data_sqlite3, 'users.csv.gz', 'edges.csv.gz', 'tweets.csv.gz')\n",
    "    \n",
    "    # Get top trending tweet\n",
    "    results = trending_tweets_impl(conn.cursor(), N=1)\n",
    "    test.equal(results.fetchone(), (\"Hillary just gave a disastrous news conference on the tarmac to make up for poor performance last night. She's being decimated by the media!\", 37903))\n",
    "\n",
    "\n",
    "@test\n",
    "def trending_tweets(cursor, topical_phrases=['Hillary', 'Clinton'], N=5):\n",
    "    \"\"\" Retrieves the top N trending tweets containing one or more of the given topical phrases.\n",
    "    Input:\n",
    "        cursor (sqlite3.Cursor): Cursor object to query the database.\n",
    "        topical_phrases (list of strings): A list of keywords identifying a topic.\n",
    "        N: Number of trending tweets to retrieve\n",
    "    Output:\n",
    "        results (sqlite3.Cursor): Cursor object which can be used to iterate over the retrieved records/tuples.\n",
    "    \"\"\"\n",
    "    front = \"\"\"\n",
    "        SELECT DISTINCT text, retweet_count+favorite_count AS trending_count \n",
    "        FROM tweets\n",
    "        WHERE \"\"\"\n",
    "    back = \" ORDER BY trending_count DESC, text ASC LIMIT \"\n",
    "    tail = str(N)+\";\"\n",
    "    sep = ' OR '\n",
    "    modified = ['text LIKE \"%'+i+'%\"' for i in topical_phrases]\n",
    "    query = front+sep.join(modified)+back+tail\n",
    "    results = cursor.execute(query)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Task C: Tweet recommendation\n",
    "How does Twitter go about populating the feed for a user? While Twitter may use a comple models to do this, in this task, we will use a Simple Tweet Recommender (STR), which recommends a user's tweets to all users who follow him/her (without checking for possible duplicates; i.e., STR may recommend the same tweet twice if two of a user's friends have posted it).\n",
    "\n",
    "In this task, you will write a query to determine the number of tweets recommended to each user. Use only the snapshot of edges and tweets we have provided to you to do the recommendation. Report the results on the users present in the users table. (Hint: The number of records in your output should match that in the \"users\" table.) The order of results does not matter.\n",
    "\n",
    "The output schema should be:\n",
    "\n",
    "|screen_name (TEXT)| num_tweets (INTEGER) |\n",
    "| :--- |:--- |\n",
    "| | | |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Left join twice : users->edges, then->tweets;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TESTING num_tweets_in_feed: PASSED 2/2\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def num_tweets_in_feed_test(num_tweets_in_feed_impl):\n",
    "    conn = get_loaded_connection(load_twitter_data_sqlite3, 'users.csv.gz', 'edges.csv.gz', 'tweets.csv.gz')\n",
    "    results = num_tweets_in_feed_impl(conn.cursor()).fetchall()\n",
    "\n",
    "    test.equal(len(results), 12403)\n",
    "    test.equal(list(filter(lambda x: x[0] == 'TrumpGolf', results)), [('TrumpGolf', 1925)])\n",
    "\n",
    "\n",
    "@test\n",
    "def num_tweets_in_feed(cursor):\n",
    "    \"\"\" Retrieves the number of tweets STR recommends to each Twitter user.\n",
    "    Input:\n",
    "        cursor (sqlite3.Cursor): Cursor object to query the database.\n",
    "    Output:\n",
    "        results (sqlite3.Cursor): Cursor object which can be used to iterate over the retrieved records/tuples.\n",
    "    \"\"\"\n",
    "    \n",
    "#     query = \"\"\"\n",
    "#         SELECT users.screen_name, COUNT(1) AS num_tweets\n",
    "#         FROM users\n",
    "#         LEFT JOIN edges ON users.screen_name = edges.screen_name\n",
    "#         LEFT JOIN tweets ON edges.friend = tweets.screen_name\n",
    "#         GROUP BY users.screen_name\n",
    "#         ORDER BY num_tweets DESC;\n",
    "#     \"\"\"e\n",
    "    query = \"\"\"\n",
    "        SELECT users.screen_name, COUNT(text) AS num_tweets\n",
    "        FROM users\n",
    "        LEFT JOIN edges ON edges.screen_name = users.screen_name \n",
    "        LEFT JOIN tweets ON tweets.screen_name = edges.friend\n",
    "        GROUP BY users.screen_name;\n",
    "    \"\"\"\n",
    "    return cursor.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Visualization\n",
    "In this question, you will load all data into pandas dataframes and analyse (and visualize!) some interesting trends using [matplotlib](http://matplotlib.org) python package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Task A: Load Twitter data using pandas \n",
    "Fill in the following method stub and return the data frames for users, edges and tweets.\n",
    "\n",
    "Pandas will treat missing values as NaNs by default. However, for this assignment, you should treat missing values (i.e., empty strings in the csv files) as empty strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_twitter_data_pandas_test(load_twitter_data_pandas_impl):\n",
    "    (users_df, edges_df, tweets_df) = load_twitter_data_pandas_impl(\n",
    "        'users.csv.gz', 'edges.csv.gz', 'tweets.csv.gz')\n",
    "    try:\n",
    "        test.equal(users_df.at[0, 'name'], 'Donald J. Trump')\n",
    "    except AttributeError:\n",
    "        test.true(False)\n",
    "\n",
    "    try:\n",
    "        test.equal(users_df.at[4, 'location'], 'DC')\n",
    "    except AttributeError:\n",
    "        test.true(False)\n",
    "\n",
    "\n",
    "@test\n",
    "def load_twitter_data_pandas(users_filepath, edges_filepath, tweets_filepath):\n",
    "    \"\"\" Loads the Twitter data from the csv files into Pandas dataframes\n",
    "    Input:\n",
    "        users_filepath (str) : absolute/relative path to users.csv file\n",
    "        edges_filepath (str) : absolute/relative path to edges.csv file\n",
    "        tweets_filepath (str) : absolute/relative path to tweets.csv file\n",
    "    Output:\n",
    "        (pd.DataFrame, pd.DataFrame, pd.DataFrame) : A tuple of three dataframes, the first one for users,\n",
    "                                                    the second for edges and the third for tweets.\n",
    "    \"\"\"\n",
    "    \n",
    "    users_df = pd.read_csv(users_filepath, compression = 'gzip')\n",
    "    edges_df = pd.read_csv(edges_filepath, compression = 'gzip')\n",
    "    tweets_df = pd.read_csv(tweets_filepath, compression = 'gzip')\n",
    "    return (users_df, edges_df, tweets_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Task B: Correlation\n",
    "Statisticians and data analysts usually like to study about correlation between different observed variables. This helps uncover interesting patterns in the data such as causal relationships (e.g., snow on the road leads to increase in number of accidents). Correlation studies are important for multiple reasons:\n",
    "- While [correlation does not imply causation](https://en.wikipedia.org/wiki/Correlation_does_not_imply_causation), a lack of correlation implies a lack of causation. This can be used to rule out many causal relationships.\n",
    "- Correlation helps with prediction. The more closely related two variables are, the easier it is to predict one from the other.\n",
    "\n",
    "In this task, we ask you to plot the friends_count (on y-axis) vs the followers_count (on x-axis) using the matplotlib package. [Here](http://matplotlib.org/examples/shapes_and_collections/scatter_demo.html) is an example to get started with scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_friends_vs_followers_test(plot_friends_vs_followers_impl):\n",
    "    (users_df, edges_df, tweets_df) = load_twitter_data_pandas('users.csv.gz', 'edges.csv.gz', 'tweets.csv.gz')\n",
    "    p = plot_friends_vs_followers_impl(users_df)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "@test\n",
    "def plot_friends_vs_followers(users_df):\n",
    "    \"\"\" Plots the friends_count (on y-axis) against the followers_count (on x-axis).\n",
    "    Input:\n",
    "        users_df (pd.DataFrame) : Dataframe containing Twitter user attributes,\n",
    "                                    as returned by load_twitter_data_pandas()\n",
    "    Output:\n",
    "        (matplotlib.collections.PathCollection) : The object returned by the scatter plot function\n",
    "    \"\"\"\n",
    "    friend = users_df['friends_count'].tolist()\n",
    "    follower = users_df['followers_count'].tolist()\n",
    "    plot = plt.scatter(follower, friend)\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see a correlation between these two variables from your scatter plot? Let's measure this quantitatively using the [Pearson's correlation coefficient](https://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient). \n",
    "\n",
    "For a set of observations $(X,Y) = [(x_1,y_1), (x_2,y_2), ... , (x_n,y_n)]$, the Pearson's correlation coefficient is a measure of the linear dependence between two variables $X$ and $Y$, giving a value between +1 and −1 inclusive, where 1 is total positive correlation, 0 is no correlation, and −1 is total negative correlation.\n",
    "\n",
    "$r=r_{xy}={\\frac {n\\sum x_{i}y_{i}-\\sum x_{i}\\sum y_{i}}{{\\sqrt {n\\sum x_{i}^{2}-(\\sum x_{i})^{2}}}~{\\sqrt {n\\sum y_{i}^{2}-(\\sum y_{i})^{2}}}}}$\n",
    "\n",
    "Now, fill in the following function to compute the Pearson's correlation coefficient between friends_count and followers_count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_coefficient(users_df):\n",
    "    \"\"\" Plots the friends_count (on y-axis) against the followers_count (on x-axis).\n",
    "    Input:\n",
    "        users_df (pd.DataFrame) : Dataframe containing Twitter user attributes,\n",
    "                                    as returned by load_twitter_data_pandas()\n",
    "    Output:\n",
    "        (double) : correlation coefficient between friends_count and followers_count\n",
    "    \"\"\"\n",
    "    friend = users_df['friends_count'].tolist()\n",
    "    follower = users_df['followers_count'].tolist()\n",
    "    n = len(friend)\n",
    "    xy = list(zip(friend,follower))\n",
    "    sumXY = sum([i[0]*i[1] for i in xy])\n",
    "    sumX = sum(friend)\n",
    "    sumY = sum(follower)\n",
    "    sumX2 = sum([i**2 for i in friend])\n",
    "    sumY2 = sum([i**2 for i in follower])\n",
    "    top = (n*sumXY)-(sumX*sumY)\n",
    "    print(top)\n",
    "    bot = (math.sqrt((n*sumX2)-sumX**2))*(math.sqrt((n*sumY2)-sumY**2))\n",
    "    r = top/bot                                      \n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Task C: Degree distribution\n",
    "If you are not familiar with graph theory and/or graph mining, skip the first paragraph.\n",
    "\n",
    "As you're familiar with graphs, you might know that the degree of a node is the number of connections it has to other nodes. A common statistic to look out for in the case of real world graphs is the degree distribution. Literature says degrees of nodes in real world graphs follow a [power law distribution](https://en.wikipedia.org/wiki/Power_law). The implication is that a scatter plot of num_users versus k (as we will define below) yields an almost straight line. In this task, we shall verify whether the given crawl of Twitter network satisfies this property.\n",
    "\n",
    "Let us call the number of friends a Twitter user has as his/her degree. The degree distribution is a histogram of the number of friends. Your task is to visualize this histogram. Use the default number of bins.\n",
    "\n",
    "Do you notice any surprising/unexpected pattern? What can you say about the way in which the Twitter data was collected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def degree_distribution_test(degree_distribution_impl):\n",
    "    (users_df, edges_df, tweets_df) = load_twitter_data_pandas('users.csv.gz', 'edges.csv.gz', 'tweets.csv.gz')\n",
    "    h = degree_distribution_impl(edges_df)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "@test\n",
    "def degree_distribution(edges_df):\n",
    "    \"\"\" Plots the distribution of .\n",
    "    Input:\n",
    "        edges_df (pd.DataFrame) : Dataframe containing Twitter edges,\n",
    "                        as returned by load_twitter_data_pandas()\n",
    "    Output:\n",
    "        (array, array, list of Patch objects) : Tuple of the values of the histogram bins, \n",
    "                        the edges of the bins and the silent list of individual patches used to create the histogram.\n",
    "    \"\"\"\n",
    "    grouped = edges_df.groupby('screen_name')\n",
    "    groups = []\n",
    "    for key, value in grouped:\n",
    "        groups.append(value)\n",
    "    data = []\n",
    "    for user in groups:\n",
    "        degree = (len(user), user.iloc[0][0])\n",
    "        data.append(degree)\n",
    "    toplot = [x[0] for x in data]\n",
    "    bins, bin_edges, patches = plt.hist(toplot)\n",
    "    return bins, bin_edges, patches"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
