{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "In this homework we are going to apply linear regression to two different problems. We'll begin by guiding you through predicting job satisfaction and the desire to be a manager among developers based on survey data. Once that's done, you will model candy preference based on composition and food science properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import gzip\n",
    "import math\n",
    "import hashlib\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "from testing.testing import test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developers! Developers! Developers!\n",
    "\n",
    "The data from this question is based on the [2019 StackOverflow Survey](https://insights.stackoverflow.com/survey/2019); accordingly, the subset bundled with this assignment is also released under the Open Database License (ODbL) v1.0.\n",
    "\n",
    "The data was made by selecting some columns from the original dataset, only retaining rows from people who described themselves as \"a developer by profession\", and replaced long responses with shorter strings. Lets begin by examining the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Age': '22',\n",
      " 'CareerSat': 'vs',\n",
      " 'CodeRevHrs': 'NA',\n",
      " 'ConvertedComp': '61000',\n",
      " 'Country': 'United States',\n",
      " 'Dependents': 'n',\n",
      " 'DevEnvironVSC': 'y',\n",
      " 'DevTypeFullStack': 'n',\n",
      " 'EdLevel': 'bachelors',\n",
      " 'EduOtherMOOC': 'y',\n",
      " 'EduOtherSelf': 'y',\n",
      " 'Extraversion': 'y',\n",
      " 'GenderIsMan': 'y',\n",
      " 'Hobbyist': 'n',\n",
      " 'MgrIdiot': 'very',\n",
      " 'MgrWant': 'n',\n",
      " 'OpSys': 'win',\n",
      " 'OpenSourcer': 'never',\n",
      " 'OrgSize': '100-499',\n",
      " 'Respondent': '4',\n",
      " 'Student': 'n',\n",
      " 'UndergradMajorIsComputerScience': 'y',\n",
      " 'UnitTestsProcess': 'n',\n",
      " 'WorkWeekHrs': '80',\n",
      " 'YearsCode': '3',\n",
      " 'YearsCodePro': '0'}\n",
      "### TESTING read_csv: PASSED 2/2\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def read_csv_test(read_csv):\n",
    "    headers, rows = read_csv()\n",
    "    test.equal(len(rows), 65679)\n",
    "    test.equal(len(headers), 26)\n",
    "\n",
    "    # Print a row:\n",
    "    pprint(dict(zip(headers, rows[0])))\n",
    "    \n",
    "@test\n",
    "def read_csv(fn=\"eggs.csv.gz\"):\n",
    "    \"\"\"read the GZipped CSV data and split it into headers and newlines.\n",
    "    \n",
    "    kwargs:\n",
    "        fn : str -- .csv.gz file to read\n",
    "    \n",
    "    returns: Tuple[headers, body] where\n",
    "      headers : Tuple[str] -- the CSV headers\n",
    "      body : List[Tuple[str,...]] -- the CSV body\n",
    "    \"\"\"\n",
    "    with gzip.open(fn, 'rt', newline=\"\", encoding='utf-8') as f:\n",
    "        csvobj = csv.reader(f)\n",
    "        headers = next(csvobj)\n",
    "        return headers, [tuple(row) for row in csvobj]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# headers, data = read_csv()\n",
    "# headers, data = np.array(headers), np.array(data)\n",
    "# wholeData = np.vstack((headers, data))\n",
    "# import pandas as pd\n",
    "# df = pd.DataFrame(wholeData)\n",
    "# new_header = df.iloc[0]\n",
    "# df.columns = new_header\n",
    "# map(type_CareerSat, df['CareerSat'].values)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our task is to predict:\n",
    "\n",
    "1. if respondents are managers or want to be a manager in the future (`MgrWant` is `y`), and\n",
    "2. if respondents are satisfied with their career (`CareerSat` is `vs` or `ss`)\n",
    "\n",
    "based on the remaining rows. We have bolded these rows in the table below.\n",
    "\n",
    "Before we can use linear regression, we must convert this into numeric data. This is the core challenge of this problem; Here's a table of rows and what they mean:\n",
    "\n",
    "\n",
    "| Column | Sample | Does/is the respondent... | Type/Values |\n",
    "| --- |:--- |:--- |:--- |\n",
    "| **CareerSat** | 'vs' | satisfied with their career? | (`vd`, `sd`, `ne`, `ss`, `vs`) -- corresponding to ({very, slightly}, {satisfied, dissatisfied}) and neutral |\n",
    "| **MgrWant** | 'n' | ...want to be a manager? | boolean |\n",
    "| Age    | '22'   | age | integer     |\n",
    "| CodeRevHrs | '2' | hours a week spent reviewing code | integer |\n",
    "| ConvertedComp | '61000' | yearly compensation in 2019 USD | integer |\n",
    "| Country | 'United States' | lives in country | string _(ignore in regression)_ |\n",
    "| Dependents | 'n' | ...have children or other dependents. | boolean |\n",
    "| DevEnvironVSC | 'y' | ...use Visual Studio Code | boolean |\n",
    "| DevTypeFullStack | 'n' | ...identify as a full-stack developer | boolean |\n",
    "| EdLevel | 'bachelors' | maximum education level | (`other`, `bachelors`, `masters`, `doctoral`) |\n",
    "| EduOtherMOOC | 'y' | ...ever taken a Massively Open Online Course | boolean |\n",
    "| EduOtherSelf | 'y' | ...ever taught themselves a new platform | boolean |\n",
    "| Extraversion | 'y' | ...prefer in-person meetings to online meetings | boolean |\n",
    "| GenderIsMan | 'y' | ...male | boolean |\n",
    "| Hobbyist | 'n' | ...write code as a hobby? | boolean |\n",
    "| MgrIdiot | 'very' | ...think their manager knows what they are doing? | (`NA`, `not`, `some`, `very`), in order of increasing confidence |\n",
    "| OpSys | 'win' | which OS do they use? | (`win`, `mac`, `tux`, `NA`), for (Windows, Mac OSX, Linux-like, NA) |\n",
    "| OpenSourcer | 'Never' | ...contribute to open-source projects? | (`never`, `year`, `month-year`, `month`), in increasing order of frequency |\n",
    "| OrgSize | '100-499' | number of employees in organization? | (`NA`, `1`, `2-9`, `10-19`, `20-99`, `100-499`, `500-999`, `1,000-4,999`, `5,000-9,999`, `10,000+`) |\n",
    "| Respondent | '4' | respondent ID from original data | integer _(ignore in regression)_ |\n",
    "| Student | 'n' | ...currently a student? | boolean |\n",
    "| UndergradMajorIsComputerScience | 'y' | ...majored in CS? | boolean |\n",
    "| UnitTestsProcess | 'n' | ...use unit tests in their job? | boolean |\n",
    "| WorkWeekHrs | '80' | hours a week worked | integer |\n",
    "| YearsCode | 3 | years since first programming | integer |\n",
    "| YearsCodePro | 0 | years programming professionally | integer |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type conversion\n",
    "\n",
    "Now for the slow data-cleaning grind that is characteristic of work as a data scientist. We begin by writing type coercion functions: functions that convert each column type into a `float` value for use in linear regression. All input values are `str`.\n",
    "\n",
    "The column types are:\n",
    "\n",
    " - _boolean_ : `y`/`NA`/`n` assigned to `+1.0`/`0.0`/`0.0`\n",
    " - _integer_ : convert to `float`, preserving value. `NA` equals `0.0`. \n",
    " - _string_ : not included in regression; we'll use it later\n",
    " - CareerSat: Map (`vd`, `sd`, `ne`, `NA`, `ss`, `vs`) to (-2.0, -1.0, 0.0, 0.0, 1.0, 2.0)\n",
    " - EdLevel: Map (`other`, `bachelors`, `masters`, `doctoral`) to (0.0, 1.0, 1.5, 2.0)\n",
    " - MgrIdiot: Map (`NA`, `not`, `some`, `very`) to (-1.0, -1.0, 0.0, 1.0)\n",
    " - OpSys: This is a category variable, we will split this into three columns (one for each possible value) and set 1.0 in the corresponding column. This is called a [one-hot encoding](https://en.wikipedia.org/wiki/One-hot). (Don't write a conversion function in this step.)  00001ï¼Œ00010\n",
    " - OpenSourcer : Map (`never`, `year`, `month-year`, `month`) to (0.0, 0.5, 1.0, 2.0)\n",
    " - OrgSize: Map each range \"$a$-$b$\" to the value $ln(a)$. Treat `NA` as `ln(1.0) = 0`. We are converting an exponentially distributed range to a linearly distributed one.\n",
    "\n",
    "All your conversion functions must throw an exception if you encounter an unexpected value. As an example, we give you the boolean conversion function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TESTING type_boolean: PASSED 4/4\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def type_boolean_test(type_boolean):\n",
    "    test.true(isinstance(type_boolean(\"y\"), float))\n",
    "    test.equal(type_boolean(\"y\"), 1.0)\n",
    "    test.equal(type_boolean(\"n\"), 0.0)\n",
    "    test.exception(lambda: type_boolean(\"5\"))\n",
    "\n",
    "@test\n",
    "def type_boolean(c):\n",
    "    if c == \"y\": return 1.0\n",
    "    elif c == \"n\": return 0.0\n",
    "    elif c == \"NA\": return 0.0\n",
    "    raise ValueError(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fill in these functions according to specification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TESTING type_integer: PASSED 6/6\n",
      "###\n",
      "\n",
      "### TESTING type_CareerSat: PASSED 6/6\n",
      "###\n",
      "\n",
      "### TESTING type_EdLevel: PASSED 5/5\n",
      "###\n",
      "\n",
      "### TESTING type_MgrIdiot: PASSED 5/5\n",
      "###\n",
      "\n",
      "### TESTING type_OpenSourcer: PASSED 5/5\n",
      "###\n",
      "\n",
      "### TESTING type_OrgSize: PASSED 6/6\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Integer\n",
    "def type_integer_test(type_integer):\n",
    "    test.true(isinstance(type_integer(\"5\"), float))\n",
    "    test.equal(type_integer(\"3\"), 3.0)\n",
    "    test.equal(type_integer(\"0\"), 0.0)\n",
    "    test.equal(type_integer(\"-4\"), -4.0)\n",
    "    test.equal(type_integer(\"NA\"), 0.0)\n",
    "    test.exception(lambda: type_integer(\"yes\"))\n",
    "\n",
    "@test\n",
    "#what we want is to convert any int type variables into float, and if the variable is NA we set it to 0.0\n",
    "def type_integer(c):\n",
    "    if c == \"NA\":\n",
    "        return 0.0\n",
    "    else :\n",
    "        return float(c)\n",
    "\n",
    "\n",
    "# CareerSat\n",
    "def type_CareerSat_test(type_CareerSat):\n",
    "    test.true(isinstance(type_CareerSat(\"vd\"), float))\n",
    "    test.equal(type_CareerSat(\"sd\"), -1.0)\n",
    "    test.equal(type_CareerSat(\"ne\"), 0.0)\n",
    "    test.equal(type_CareerSat(\"ss\"), 1.0)\n",
    "    test.equal(type_CareerSat(\"vs\"), 2.0)\n",
    "    test.exception(lambda: type_CareerSat(\"yes\"))\n",
    "\n",
    "@test\n",
    "def type_CareerSat(c):\n",
    "    mapping = {\"vd\":-2.0, \"sd\":-1.0,\n",
    "              \"ne\" : 0.0, \"NA\":0.0,\n",
    "              \"ss\":1.0, \"vs\":2.0}\n",
    "    return mapping[c]\n",
    "\n",
    "\n",
    "# EdLevel\n",
    "def type_EdLevel_test(type_EdLevel):\n",
    "    test.true(isinstance(type_EdLevel(\"other\"), float))\n",
    "    test.equal(type_EdLevel(\"bachelors\"), 1.0)\n",
    "    test.equal(type_EdLevel(\"masters\"), 1.5)\n",
    "    test.equal(type_EdLevel(\"doctoral\"), 2.0)\n",
    "    test.exception(lambda: type_EdLevel(\"yes\"))\n",
    "\n",
    "@test\n",
    "def type_EdLevel(c):\n",
    "    mapping = {\"other\" : 0.0,  \"bachelors\": 1.0, \n",
    "               \"masters\": 1.5, \"doctoral\": 2.0}\n",
    "    return mapping[c]\n",
    "\n",
    "\n",
    "# MgrIdiot\n",
    "def type_MgrIdiot_test(type_MgrIdiot):\n",
    "    test.true(isinstance(type_MgrIdiot(\"NA\"), float))\n",
    "    test.equal(type_MgrIdiot(\"not\"), -1.0)\n",
    "    test.equal(type_MgrIdiot(\"some\"), 0.0)\n",
    "    test.equal(type_MgrIdiot(\"very\"), 1.0)\n",
    "    test.exception(lambda: type_MgrIdiot(\"yes\"))\n",
    "\n",
    "@test\n",
    "def type_MgrIdiot(c):\n",
    "    mapping = {\"NA\" : -1.0, \"not\": -1.0, \"some\": 0.0, \"very\": 1.0}\n",
    "    return mapping[c]\n",
    "\n",
    "\n",
    "\n",
    "# OpenSourcer\n",
    "def type_OpenSourcer_test(type_OpenSourcer):\n",
    "    test.true(isinstance(type_OpenSourcer(\"never\"), float))\n",
    "    test.equal(type_OpenSourcer(\"year\"), 0.5)\n",
    "    test.equal(type_OpenSourcer(\"month-year\"), 1.0)\n",
    "    test.equal(type_OpenSourcer(\"month\"), 2.0)\n",
    "    test.exception(lambda: type_OpenSourcer(\"yes\"))\n",
    "\n",
    "@test\n",
    "def type_OpenSourcer(c):\n",
    "    mapping = {\"never\" : 0.0, \"year\" : 0.5, \"month-year\" : 1.0, \"month\" : 2.0}\n",
    "    return mapping[c]\n",
    "\n",
    "\n",
    "# OrgSize\n",
    "def type_OrgSize_test(type_OrgSize):\n",
    "    test.true(isinstance(type_OrgSize(\"1\"), float))\n",
    "    test.equal(type_OrgSize(\"NA\"), 0)\n",
    "    test.equal(type_OrgSize(\"2-9\"), 0.6931471805599453)\n",
    "    test.equal(type_OrgSize(\"100-499\"), 4.605170185988092)\n",
    "    test.equal(type_OrgSize(\"10,000+\"), 9.210340371976184)\n",
    "    test.exception(lambda: type_OrgSize(\"yes\"))\n",
    "\n",
    "@test\n",
    "def type_OrgSize(c):\n",
    "    '''input arg: string, \"100-200\" '''\n",
    "    if c == \"NA\":\n",
    "        return np.log(1)\n",
    "    c = c.replace(\"+\",\"\").replace(\",\",\"\")\n",
    "    try:\n",
    "        whereStop = c.index(\"-\")\n",
    "        digit = c[:whereStop]\n",
    "    except:\n",
    "        try:\n",
    "            if c.isnumeric():\n",
    "                digit = int(c)\n",
    "        except:\n",
    "            raise ValueError('Invalid Input')\n",
    "\n",
    "    return np.log(int(digit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use these to convert the data into floating-point numbers. \n",
    "\n",
    "This is also where we deal with `OpSys`; from the one column in the source, create three columns (called `OpSysWin`, `OpSysMac`, and `OpSysTux`, corresponding to the values `win`, `mac`, `tux`. Other values can be ignored.) For each row, at most one of the cells must be 1.0, and the others must be 0.0. If the value in the cell is `NA`, then all the cells must be 0.0.\n",
    "\n",
    "This is called a [one-hot encoding](https://en.wikipedia.org/wiki/One-hot) and is a common way to handle category variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a = [\"a\", \"b\"]\n",
    "# \"b\" in a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TESTING convert_data_stackoverflow: PASSED 3/3\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def quick_checksum(st):\n",
    "    return hashlib.md5((\" \".join(sorted(st))).encode()).hexdigest()\n",
    "\n",
    "def convert_data_stackoverflow_test(convert_data_stackoverflow):\n",
    "    headers, rows = convert_data_stackoverflow(*read_csv())\n",
    "    # If this test fails, your headers are incorrect:\n",
    "    test.equal(quick_checksum(headers), \"5f9fc24f9e8dae961c2a778f493940ed\")\n",
    "    # Type check:\n",
    "    test.true(all(all(isinstance(v, float) for v in r) for r in rows))\n",
    "    # Operating System columns:\n",
    "    for row in rows:\n",
    "        d = dict(zip(headers, row))\n",
    "        if sorted([d[\"OpSysWin\"], d[\"OpSysMac\"], d[\"OpSysTux\"]]) not in [[.0, .0, 1.], [0.]*3]:\n",
    "            test.true(False)\n",
    "            break\n",
    "    else:\n",
    "        test.true(\"There is correctly at most one OpSys* column set to 1.0\")\n",
    "    \n",
    "\n",
    "@test\n",
    "def convert_data_stackoverflow(headers, data):\n",
    "    \"\"\"convert the data into \n",
    "    \n",
    "    args:\n",
    "        header : List[str] -- the header for each column in the CSV\n",
    "        data : List[Tuple[str]] -- the CSV data, where each inner list corresponds to a row in the CSV file.\n",
    " \n",
    "    returns: Tuple[headers, body] where\n",
    "      headers : List[str] -- the new headers, dropping the Country and Respondent headers and expanding \n",
    "      body : List[List[str,...]] -- the CSV body\n",
    "    \"\"\"\n",
    "    #first we need to check if the original data width is the same as the length of ther header\\\n",
    "    assert len(headers) == len(data[0])\n",
    "    \n",
    "    #needed to be dropped:\n",
    "    dropping = [\"Country\", \"Respondent\", \"headers\"]\n",
    "    \n",
    "    #we need to track which index is indicating which column name \n",
    "    whichColumn = {} \n",
    "    for i in range(len(headers)):\n",
    "        whichColumn[i] = headers[i]\n",
    "        \n",
    "    #method map, as different column has different method; also not including the drpped and 'OpSys'\n",
    "    #the 'OpSys' needs to be processed into on hot vector\n",
    "    whichMethod = {'CareerSat': type_CareerSat, \"MgrWant\": type_boolean, \"Hobbyist\":type_boolean,\n",
    "                  'OpenSourcer': type_OpenSourcer, \"Student\" : type_boolean, \"EdLevel\": type_EdLevel,\n",
    "                  'UndergradMajorIsComputerScience': type_boolean, 'EduOtherMOOC': type_boolean,\n",
    "                  'OrgSize': type_OrgSize, 'DevTypeFullStack': type_boolean, 'YearsCode': type_integer,\n",
    "                  'MgrIdiot': type_MgrIdiot, 'ConvertedComp' : type_integer, 'WorkWeekHrs' : type_integer,\n",
    "                  'CodeRevHrs': type_integer, 'UnitTestsProcess': type_boolean, 'Extraversion': type_boolean,\n",
    "                  'Age': type_integer, 'GenderIsMan': type_boolean, 'Dependents': type_boolean,\n",
    "                  'OpSys':'oneHot', 'EduOtherSelf':type_boolean, 'YearsCodePro': type_integer,\n",
    "                  'DevEnvironVSC': type_boolean}\n",
    "    \n",
    "    #one hot decode\n",
    "    oneHotHash = {'win':[1.0, 0.0, 0.0], 'mac' : [0.0, 1.0, 0.0], 'tux': [0.0, 0.0, 1.0]}\n",
    "    \n",
    "    #Now all the hash is\n",
    "    #one hot vector, which inherently would introduce 3 more columns. Also, this also means that if the 'whichMethod' hash does\n",
    "    #not contain the column name, that just means that it is the 'OpSys'\n",
    "    new_header = []\n",
    "    for col in headers:\n",
    "        if col != \"Country\" and  col != \"Respondent\" and col != \"OpSys\":\n",
    "            new_header.append(col)\n",
    "    new_header.extend([\"OpSysWin\", \"OpSysMac\", \"OpSysTux\"])\n",
    "    \n",
    "    newDataReturn = []\n",
    "    for rowData in data:\n",
    "        newRowData = []\n",
    "        for i in range(len(data[0])):\n",
    "            #we do not need to process the data under the dropped column\n",
    "            if whichColumn[i] in dropping:\n",
    "                continue\n",
    "            thisColumn = whichColumn[i]\n",
    "            thisMethod = whichMethod[thisColumn]\n",
    "            if thisMethod == 'oneHot':\n",
    "                if rowData[i] in oneHotHash:\n",
    "                    oneHot = oneHotHash[rowData[i]]\n",
    "                else:\n",
    "                    oneHot = [0.0,0.0,0.0]\n",
    "            else:       \n",
    "                newData = thisMethod(rowData[i])\n",
    "                newRowData.append(newData)    \n",
    "        newRowData.extend(oneHot)\n",
    "        newDataReturn.append(newRowData)\n",
    "        \n",
    "    return (new_header, newDataReturn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data\n",
    "\n",
    "Now we prepare the converted data for regression. In this step, we:\n",
    "\n",
    " 1. split this into training and validation sets,\n",
    " 2. convert it to a Numpy `ndarray` with underlying type `np.float32`,\n",
    " 3. split each set into the predicted columns and the feature columns.\n",
    "\n",
    "We will save the first 20% of the dataset (rounded down) as the validation set and keep the remaining as the training set. (Note that it is common practice to randomize the dataset; this has already been done. Don't shuffle the dataset for this assignment.)\n",
    "\n",
    "Ensure that the underlying type of the `ndarray` is `np.float32`, not the default `np.float64`. We do not need the added precision of 64-bit floating point numbers for this problem, and using the smaller numbers will speed up computation and reduce the amount of memory we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TESTING split_data: PASSED 6/6\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def split_data_test(split_data):\n",
    "    headers, rows = convert_data_stackoverflow(*read_csv())\n",
    "    l = len(rows)\n",
    "    \n",
    "    val, train = split_data(rows)\n",
    "    test.equal(len(val), l // 5)\n",
    "    test.true(isinstance(val, np.ndarray))\n",
    "    test.equal(val.dtype, np.float32)\n",
    "    test.equal(len(train), l - (l // 5))\n",
    "    test.true(isinstance(train, np.ndarray))\n",
    "    test.equal(train.dtype, np.float32)\n",
    "\n",
    "@test\n",
    "def split_data(data):\n",
    "    \"\"\"split the data into training and validation sets, and convert them to np.ndarray. (Step 1 and 2 above.)\n",
    "\n",
    "    args:\n",
    "        data : List[List[str]] -- the CSV data, where each inner list corresponds to a row in the CSV file.\n",
    "\n",
    "    returns: Tuple[val, train] where\n",
    "      val  : np.ndarray[num_val_rows, num_features] -- the first 20% of the dataset (rounded down)\n",
    "      train : np.ndarray[num_train_rows, num_features] -- the remaining rows from data\n",
    "    \n",
    "    Ensure that the underlying type of the output is np.float32, not the default np.float64.\n",
    "    \"\"\"\n",
    "    valLength = int(len(data) * 0.2)\n",
    "    valSet = np.asarray(data[:valLength], dtype = np.float32)\n",
    "    trainSet = np.asarray(data[valLength:], dtype = np.float32)\n",
    "    return(valSet, trainSet)\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TESTING separate_objective: PASSED 10/10\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def separate_objective_test(separate_objective):\n",
    "    headers, rows = convert_data_stackoverflow(*read_csv())\n",
    "    val, train = split_data(rows)\n",
    "\n",
    "    for subset in [val, train]:\n",
    "        subset_headers, subset_features, subset_objectives = separate_objective(headers, subset, [\"CareerSat\", \"MgrWant\"])\n",
    "\n",
    "        test.true(isinstance(subset_objectives, tuple))\n",
    "        test.equal(len(subset_objectives), 2)\n",
    "        test.true(\"CareerSat\" not in subset_headers)\n",
    "        test.true(\"MgrWant\" not in subset_headers)\n",
    "        test.equal(subset_features.shape[1], 24)\n",
    "\n",
    "@test\n",
    "def separate_objective(headers, data, objectives):\n",
    "    \"\"\"split the objective columns from the headers and data. (Step 1 and 2 above.)\n",
    "\n",
    "    args:\n",
    "        headers    : List[str] -- the headers for the data, used to find the objective columns from the data array\n",
    "        data       : np.ndarray[num_rows, num_columns] -- the data\n",
    "        objectives : the columns to extract from the data, list of strings\n",
    "\n",
    "    returns: Tuple[o_headers, o_features, o_objectives] where\n",
    "      o_headers  : List[str] -- a list of headers without the objective columns\n",
    "      o_features : np.ndarray[num_train_rows, num_features] -- the remaining columns from data. (num_features = num_columns - len(objectives))\n",
    "      o_objectives : Tuple[np.ndarray[num_train_rows], ...] -- a list of objective columns from the data, each element is a 1-dimensional np.ndarray corresponding to the entry in objectives.\n",
    "     \"\"\"\n",
    "    #the needed deleted items are saved in the objectives as a List<String>\n",
    "    o_headers = []    #the headers without the objective columns \n",
    "    whichColumn = set() #we need to track the deleted column index\n",
    "    \n",
    "    for idx, title in enumerate(headers):\n",
    "        if title in objectives:\n",
    "            whichColumn.add(idx)\n",
    "        else:\n",
    "            o_headers.append(title)\n",
    "    \n",
    "    #now we need to extact out the needed features   m by n, m samples, n features\n",
    "    #and we need the labels, m by nLabels\n",
    "    o_features = []\n",
    "    o_objectives = []\n",
    "    for row in data:\n",
    "        target_data = []\n",
    "        features = []\n",
    "        for i in range(len(row)):\n",
    "            #if this idx is in the removed hash, we know it is the label\n",
    "            if i in whichColumn:\n",
    "                target_data.append(row[i])\n",
    "            else:\n",
    "                features.append(row[i])\n",
    "        o_features.append(features)\n",
    "        o_objectives.append(target_data)\n",
    "        \n",
    "#     print(\"labels in \", np.array(o_objectives).T.shape)\n",
    "#     print(\"features in \", np.array(o_features).shape)\n",
    "    o_objectives = tuple(np.array(o_objectives).T)\n",
    "    o_features = np.array(o_features)\n",
    "\n",
    "    return (o_headers, o_features, o_objectives)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n",
    "Now you will finally implement a linear regression. As a reminder, linear regression models the data as\n",
    "\n",
    "$$\\mathbf y = \\mathbf X\\mathbf \\beta + \\mathbf \\epsilon$$\n",
    "\n",
    "where $\\mathbf y$ is a vector of outputs, $\\mathbf X$ is also known as the design matrix, $\\mathbf \\beta$ is a vector of parameters, and $\\mathbf \\epsilon$ is noise. We will be estimating $\\mathbf \\beta$ using Ordinary Least Squares, and we recommending following the matrix notation for this problem (https://en.wikipedia.org/wiki/Ordinary_least_squares).\n",
    "\n",
    "You are not allowed to use `scipy` in your submission for this assignment, but you are encouraged to use it to test your solution. Make sure that you only ever `import scipy` inside a `_test` function.\n",
    "\n",
    "Hints:\n",
    "\n",
    " 1. You should use `np.linalg.solve` to calculate `beta`.\n",
    " 2. Feel free to add `1e-4*np.eye(...)` to the coefficient matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LinearRegression():\n",
    "    \"\"\" Perform linear regression and predict the output on unseen examples. \n",
    "    \n",
    "    attributes: \n",
    "        beta (np.ndarray) : vector containing parameters for the features\n",
    "    \"\"\"\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\" Train the linear regression model by computing the estimate of the parameters\n",
    "        You should store the model parameters in self.beta, overwriting parameters as necessary.\n",
    "\n",
    "        args: \n",
    "            X (np.ndarray[num_examples, num_columns]) : matrix of training data\n",
    "            y (np.ndarray[num_examples]) : vector of output variables\n",
    "\n",
    "        return: LinearRegression -- returns itself (for convenience)\n",
    "        \"\"\"\n",
    "        #extract the m samples and n features out \n",
    "        m,n = X.shape\n",
    "        #adding the 1e-4\n",
    "        X = X + 1e-4 * np.eye(m,n)\n",
    "        #construct the matrix\n",
    "        A = np.zeros((n,n))\n",
    "        for i in range(m):\n",
    "            A += np.outer(X[i],X[i])\n",
    "           \n",
    "        #convert the y into the same dimension - > mSampe * 1\n",
    "        yy = np.expand_dims(y, 1)\n",
    "        #element wise production and sum all the rows \n",
    "        b = sum(X * yy)\n",
    "        self.beta = np.linalg.solve(A,b)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X_p): \n",
    "        \"\"\" Use the learned model to predict the output of X_p\n",
    "\n",
    "        args: \n",
    "            X_p (np.ndarray[num_examples, num_columns]) matrix of test/validation data where each row corresponds to an example\n",
    "\n",
    "        return: \n",
    "            (np.ndarray[num_examples]) vector of predicted outputs\n",
    "        \"\"\"\n",
    "        y_pred = X_p @ self.beta    # -> m by 1 predictions\n",
    "        print(y_pred.shape)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Don't remove this function; we use it for the auto-grader.\n",
    "def linear_regression_instance():\n",
    "    return LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Functions\n",
    "\n",
    "One last part to this: linear regression minimizes the mean-squared-error. Write a function that calculates the mean mean-squared-error when given a prediction and a ground-truth vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground Truth shape (10,)\n",
      "prediction shape (10,)\n",
      "ground Truth shape (10,)\n",
      "prediction shape (10,)\n",
      "### TESTING mean_squared_error: PASSED 2/2\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def mean_squared_error_test(mean_squared_error):\n",
    "    test.equal(mean_squared_error(np.ones(10), np.ones(10)), 0)\n",
    "    test.equal(mean_squared_error(np.ones(10), np.zeros(10)), 1)\n",
    "\n",
    "@test\n",
    "def mean_squared_error(pred, ground_truth):\n",
    "    \"\"\" calculate the mean mean-squared-error between pred and ground_truth\n",
    "    \n",
    "    args:\n",
    "      pred : np.ndarray[num_examples] -- the predictions\n",
    "      ground_truth : np.ndarray[num_examples] -- the ground truth values\n",
    "      \n",
    "    returns: float -- the average mean-squared-error between predictions and ground_truth values.\n",
    "    \"\"\"\n",
    "    print(\"ground Truth shape\", ground_truth.shape)\n",
    "    print(\"prediction shape\",pred.shape)\n",
    "    MSE = np.square(np.subtract(ground_truth, pred)).mean()\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together\n",
    "\n",
    "And finally, lets run the entire pipeline end-to-end. You should put all the functions you have written so far together to:\n",
    "\n",
    "1. read and split the dataset,\n",
    "2. train two separate models on the training set, one to predict `MgrWant` and the other to predict `CareerSat`,\n",
    "3. perform inference on the validation set, and\n",
    "4. return the mean-squared error for each.\n",
    "\n",
    "Remember not to include both columns `MgrWant` and `CareerSat` when training models to predict either column. (i.e. when training `MgrWant`, you should not include `CareerSat` and vice-versa.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13135,)\n",
      "(13135,)\n",
      "ground Truth shape (13135,)\n",
      "prediction shape (13135,)\n",
      "ground Truth shape (13135,)\n",
      "prediction shape (13135,)\n",
      "### TESTING linear_regression_run: PASSED 0/2\n",
      "# 0\t: Assertion failed\n",
      "# 1\t: Assertion failed\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def linear_regression_run_test(linear_regression_run):\n",
    "    mse_mgr, mse_sat = linear_regression_run(*read_csv())\n",
    "    test.true(np.abs(mse_sat - 0.07214) < 1e-4)\n",
    "    test.true(np.abs(mse_mgr - 1.29104) < 1e-4)\n",
    "\n",
    "@test\n",
    "def linear_regression_run(headers, rows):\n",
    "    \"\"\" Perform linear regression on (headers, rows), and return the MSE on the validation set for both `MgrWant` and `CareerSat`. \n",
    "\n",
    "    args: \n",
    "        headers : List[str] -- headers from CSV file\n",
    "        rows : np.ndarray[num_examples, num_columns] -- data from the CSV file\n",
    "        \n",
    "    return: Tuple[MSEMgrWant, MSECareerSat], where\n",
    "        MSEMgrWant : float -- the MSE between the predictions and the ground truth values for the column `MgrWant`.\n",
    "        MSECareerSat : float -- the MSE between the predictions and the ground truth values for the column `CareerSat`.\n",
    "    \"\"\"\n",
    "    #fisrt step is to conver all text data and drop non- needed data points\n",
    "    newHeader, data = convert_data_stackoverflow(headers, rows)\n",
    "    \n",
    "    #and then let us split the data into train and val set\n",
    "    valSet, trainSet = split_data(data)\n",
    "    \n",
    "    #get the features and labels out\n",
    "    trainHeader, trainFeatures, trainLabels = separate_objective(newHeader, trainSet, objectives = [\"MgrWant\",\"CareerSat\"])\n",
    "    valHeader, valFeatures, valLabels = separate_objective(newHeader, valSet, objectives = [\"MgrWant\",\"CareerSat\"])\n",
    "    \n",
    "    #get the labels for mgr want and the careersat labels out \n",
    "    mrgLabelTrain, carLabelTrain = trainLabels[0], trainLabels[1]\n",
    "    mrgLabelVal, carLabelVal = valLabels[0], valLabels[1]\n",
    "    \n",
    "    #build our two models\n",
    "    mrgModel =linear_regression_instance()\n",
    "    carModel = linear_regression_instance()\n",
    "    \n",
    "    #trainout two models\n",
    "    mrgModel = mrgModel.train(trainFeatures, mrgLabelTrain)\n",
    "    carModel = carModel.train(trainFeatures, carLabelTrain)\n",
    "    \n",
    "    #prediction\n",
    "    mrgPred = mrgModel.predict(valFeatures)\n",
    "    carPred = carModel.predict(valFeatures)\n",
    "    \n",
    "    #calculation\n",
    "    mrgError = mean_squared_error(mrgPred, mrgLabelVal)\n",
    "    carError = mean_squared_error(carPred, carLabelVal)\n",
    "\n",
    "    return carError, mrgError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `MgrWant` is a binary variable, with range $[-1, 1]$, and `CareerSat` has range $[-2, 2]$; relative to the range, the mean-squared error for `CareerSat` is much smaller than `MgrWant`. This means that we can better predict `CareerSat` than `MgrWant`. Great!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn\n",
    "\n",
    "Now that we've walked through this once with a large dataset, it is your turn to do this. You will be using [FiveThirtyEight's The Ultimate Halloween Candy Power Ranking](https://www.kaggle.com/fivethirtyeight/the-ultimate-halloween-candy-power-ranking/), included (and shuffled) as `candy.csv.gz`. (The dataset is Copyright (c) 2014 ESPN Internet Ventures. Our shuffled version is released under the MIT License.)\n",
    "\n",
    "From the original documentation, here is a description of the columns:\n",
    "\n",
    "| Column | Description | type |\n",
    "| --- |:--- |:--- |\n",
    "| **`winpercent`** | The overall win percentage according to 269,000 matchups. | float |\n",
    "| `competitorname` | The bar name | string (don't use this) |\n",
    "| `chocolate` | Does it contain chocolate? | boolean (`y`, `n`) |\n",
    "| `fruity` | Is it fruit flavored? | boolean (`y`, `n`) |\n",
    "| `caramel` | Is there caramel in the candy? | boolean (`y`, `n`) |\n",
    "| `peanutalmondy` | Does it contain peanuts, peanut butter or almonds? | boolean (`y`, `n`) |\n",
    "| `nougat` | Does it contain nougat? | boolean (`y`, `n`) |\n",
    "| `crispedricewafer` | Does it contain crisped rice, wafers, or a cookie component? | boolean (`y`, `n`) |\n",
    "| `hard` | Is it a hard candy? | boolean (`y`, `n`) |\n",
    "| `bar` | Is it a candy bar? | boolean (`y`, `n`) |\n",
    "| `pluribus` | Is it one of many candies in a bag or box? | boolean (`y`, `n`) |\n",
    "| `sugarpercent` | The percentile of sugar it falls under within the data set. | float |\n",
    "| `pricepercent` | The unit price percentile compared to the rest of the set. | float |\n",
    "\n",
    "\n",
    "You must predict `winpercent` using exactly **four** other columns. Use the first 20% of the dataset as the validation set (the dataset has already been shuffled for you). As output, you should provide the names of the columns and the validation of the MSE. Your MSE must be no more than `330`.\n",
    "\n",
    "You should convert boolean columns using `type_boolean`, and `LinearRegression` to perform the regression. Don't implement a bias term/constant column. Feel free to create new helper functions as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['competitorname', 'chocolate', 'fruity', 'caramel', 'peanutyalmondy', 'nougat', 'crispedricewafer', 'hard', 'bar', 'pluribus', 'sugarpercent', 'pricepercent', 'winpercent']\n",
      "(68,)\n",
      "ground Truth shape (68,)\n",
      "prediction shape (68,)\n",
      "MSE Loss 287.42907494476367\n",
      "### TESTING candy: PASSED 3/3\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def candy_test(candy):\n",
    "    headers, mse = candy(*read_csv(\"candy.csv.gz\"))\n",
    "    #print((headers, mse))\n",
    "    test.true(len(headers) == 4)\n",
    "    test.true(\"winpercent\" not in headers)\n",
    "    test.true(mse < 330.)\n",
    "\n",
    "def conversion(dataPoint):\n",
    "    \n",
    "    try:\n",
    "        dataPoint = type_boolean(dataPoint)\n",
    "    except:\n",
    "        dataPoint = type_integer(dataPoint)\n",
    "\n",
    "    return dataPoint\n",
    "                \n",
    "@test\n",
    "def candy(headers, data):\n",
    "    \"\"\" predict winpercent using no more than four other columns\n",
    "    \n",
    "    args:\n",
    "        headers : List[str] -- headers read from the csv file\n",
    "        data : List[List[str]] -- data from the csv file\n",
    "\n",
    "    returns: Tuple[selected_headers, mse]\n",
    "        selected_headers : List[str] -- the headers of at most four columns used to train the model\n",
    "        mse : float -- the mean-squared error when the columns in selected_headers are used to predict `winpercent`\n",
    "    \"\"\"\n",
    "    print(headers)\n",
    "    headerMap = {}\n",
    "    for i in range(len(headers)):\n",
    "        headerMap[i] = headers[i]\n",
    "    \n",
    "    dataSet = []\n",
    "    label = []\n",
    "    selectedHeaders = ['chocolate', 'fruity','sugarpercent','pricepercent']\n",
    "    \n",
    "    #now we want to get the trainning datapoints\n",
    "    for row in data:\n",
    "        rowData = []\n",
    "        rowLabel = []\n",
    "        for i in range(len(row)):\n",
    "            thisColumn = headerMap[i]\n",
    "            if thisColumn in selectedHeaders:\n",
    "                rowData.append(conversion(row[i]))\n",
    "            if thisColumn == 'winpercent':\n",
    "                rowLabel.append(conversion(row[i]))\n",
    "        dataSet.append(rowData)\n",
    "         #this is important cuz we should not use append method, which would lead to [[],[],[]].\n",
    "         #but we just want a list of numbers, not a list of list \n",
    "        label.extend(rowLabel)  \n",
    "    \n",
    "    valSet, trainSet = split_data(dataSet)\n",
    "    valLabel, trainLabel = split_data(label)\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model = model.train(trainSet, trainLabel)\n",
    "    prediction = model.predict(valSet)\n",
    "    \n",
    "    error = mean_squared_error(prediction, valLabel)\n",
    "    print(\"MSE Loss {}\".format(error))\n",
    "    return selectedHeaders, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
